{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "audio_mfcc_models.ipynb",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "08vsvdRmyDvC"
      },
      "source": [
        "import os\n",
        "import pathlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from copy import deepcopy\n",
        "from tqdm import tqdm\n",
        "\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from IPython import display\n",
        "\n",
        "from tensorflow.python.ops import gen_audio_ops as audio_ops\n",
        "#from tensorflow.op.audio import Mfcc\n",
        "from tensorflow.python.util import compat\n",
        "\n",
        "from keras import backend as K\n",
        "import datetime\n",
        "import time\n",
        "import pandas as pd\n",
        "import io\n",
        "#tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "# Set seed for experiment reproducibility\n",
        "seed = 42\n",
        "tf.random.set_seed(seed)\n",
        "np.random.seed(seed)\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class config:\n",
        "  DIRECTORY_PATH = \"./KeyWord Spotting\"\n",
        "  DATADIR_PATH = DIRECTORY_PATH + \"/data\"\n",
        "  model_name = \"tiny\"\n",
        "  BASELINE_CHECKPOINT_PATH = DIRECTORY_PATH + \"/\" + model_name + \"/\"\n",
        "  POST_TRAINING_QUANTIZATION_PATH = DIRECTORY_PATH + \"/models/post_training_quantization\"\n",
        "\n",
        "  TRAINING_DATA_SIZE = 0.8\n",
        "  VALIDATION_DATA_SIZE = 0.2\n",
        "  TEST_DATA_SIZE = 0.2\n",
        "  BATCH_SIZE = 64\n",
        "  NUM_EPOCHS = 150\n",
        "  LEARNING_RATE = 0.001\n",
        "  commands = ['yes', 'up', 'right', 'stop', 'down', 'go', 'left', 'no']\n",
        "  AUTOTUNE = tf.data.AUTOTUNE\n",
        "  log_dir = DIRECTORY_PATH+\"/logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "  file_writer = tf.summary.create_file_writer(log_dir + '/metrics')\n",
        "  file_writer_image = tf.summary.create_file_writer(log_dir + \"/images\")\n",
        "  file_writer.set_as_default()\n",
        "\n",
        "class Params:\n",
        "  sample_rate: float\n",
        "  stft_window_useconds : float\n",
        "  stft_hop_useconds: float\n",
        "  mel_bands : int\n",
        "  mel_min_hz : float\n",
        "  mel_max_hz : float\n",
        "  log_offset : float = 0.001\n",
        "  patch_window_seconds : float = 0.96\n",
        "  path_hop_seconds : float = 0.48\n",
        "\n",
        "  def __init__(self, sample_rate,stft_window,stft_hop,mel_bins,min_hz,max_hz):\n",
        "     self.sample_rate = sample_rate\n",
        "     self.stft_window_useconds = stft_window\n",
        "     self.stft_hop_useconds = stft_hop\n",
        "     self.mel_bands = mel_bins\n",
        "     self.mel_min_hz = min_hz\n",
        "     self.mel_max_hz = max_hz\n",
        "\n",
        "  @property\n",
        "  def patch_frames(self):\n",
        "    return (int(round(self.patch_window_seconds / self.stft_hop_seconds)))\n",
        "\n",
        "mel_bins =40\n",
        "max_hz = 8000\n",
        "min_hz = 0\n",
        "stft_window =30\n",
        "stft_hop = 10\n",
        "sample_rate = 16000\n",
        "\n",
        "_params = Params(sample_rate,stft_window,stft_hop,mel_bins,min_hz,max_hz)\n",
        "kws_config = config\n"
      ],
      "metadata": {
        "id": "IajqvdkG6HfA"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftWCo8Op_-Rv"
      },
      "source": [
        "def download_data(data_dir):\n",
        "  \"\"\"\n",
        "  Function to load the train and test dataset\n",
        "  \"\"\"\n",
        "  if not data_dir.exists():\n",
        "    tf.keras.utils.get_file(\n",
        "      'mini_speech_commands.zip',\n",
        "      origin=\"http://storage.googleapis.com/download.tensorflow.org/data/mini_speech_commands.zip\",\n",
        "      extract=True,\n",
        "      cache_dir='.', cache_subdir=data_dir)\n",
        "\n",
        "def get_commands(data_dir):\n",
        "  \"\"\"\n",
        "  Function to load labels\n",
        "  \"\"\"\n",
        "  if pathlib.Path(data_dir).exists():\n",
        "     commands = np.array(tf.io.gfile.listdir(str(data_dir)))\n",
        "     commands = commands[commands != 'README.md']\n",
        "     print('Commands:', commands)\n",
        "     return commands"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CS3Dqi41HUO"
      },
      "source": [
        "def get_audio(data_dir):\n",
        "  \"\"\"\n",
        "   function to extract the audio files and into a list\n",
        "  \"\"\"\n",
        "  files = []\n",
        "  #for i in commands:\n",
        "  #  filenames += tf.io.gfile.glob(str(data_dir) + '/' + i + '/*')\n",
        "  files = tf.io.gfile.glob(str(data_dir) + '/*/*')\n",
        "  files = tf.random.shuffle(files)\n",
        "  num_samples = len(files)\n",
        "  print('Number of total examples:', num_samples)\n",
        "  commands = get_commands(data_dir)\n",
        "  print('Number of examples per label:',\n",
        "          len(tf.io.gfile.listdir(str(data_dir/commands[0]))))\n",
        "  return files\n",
        "\n",
        "#go_filenames = tf.io.gfile.glob(str(data_dir) + '/go/*')\n",
        "#no_filenames = tf.io.gfile.glob(str(data_dir) + '/no/*')\n",
        "#print('Example file tensor:', filenames[0])\n",
        "\n",
        "# Obtain Training and Validation Data Splits\n",
        "def get_data_split(data_dir):\n",
        "  \"\"\"\n",
        "   Obtain Training and Validation Data Splits\n",
        "  \"\"\"\n",
        "  download_data(pathlib.Path(data_dir))\n",
        "  data_dir = data_dir + '/mini_speech_commands'\n",
        "  audio_files = get_audio(pathlib.Path(data_dir))\n",
        "  total_data = len(audio_files)\n",
        "  train_size = int(kws_config.TRAINING_DATA_SIZE*total_data)\n",
        "  val_size = int(kws_config.VALIDATION_DATA_SIZE*total_data)\n",
        "  test_size = int(kws_config.TEST_DATA_SIZE*total_data)\n",
        "  train_files = audio_files[:train_size]\n",
        "  val_files = audio_files[train_size:train_size+val_size]\n",
        "  test_files = audio_files[-test_size:]\n",
        "  print('Training set size', len(train_files))\n",
        "  print('Validation set size', len(val_files))\n",
        "  print('Test set size', len(test_files))\n",
        "  return train_files,val_files,test_files\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpDd43EI2yWc"
      },
      "source": [
        "#reading audio files\n",
        "# tf.audio.decode_wav convert wav file to numberical tensor\n",
        "\n",
        "# sample rate of the wave is 16khz values representing (amplitude) -32768, 32767\n",
        "#tf.audio.decode_wav normalize the values to the range [-1,1]\n",
        "\n",
        "def decode_audio(audio_wave):\n",
        "  audio_wav, _ = tf.audio.decode_wav(audio_wave,desired_channels=1,desired_samples=16000)\n",
        "  return tf.squeeze(audio_wav, axis=-1)\n",
        "  #foreground_volume_placeholder_ = tf.compat.v1.placeholder(\n",
        "  #        tf.float32, [], name='foreground_volume')\n",
        "  #scaled_foreground = tf.multiply(audio_wave,\n",
        "  #                                    foreground_volume_placeholder_)\n",
        "      # Shift the sample's start position, and pad any gaps with zeros.\n",
        "  #time_shift_padding_placeholder_ = tf.compat.v1.placeholder(\n",
        "  #        tf.int32, [2, 2], name='time_shift_padding')\n",
        "  #time_shift_offset_placeholder_ = tf.compat.v1.placeholder(\n",
        "  #        tf.int32, [2], name='time_shift_offset')\n",
        "  #padded_foreground = tf.pad(\n",
        "  #        tensor=scaled_foreground,\n",
        "  #        paddings=time_shift_padding_placeholder_,\n",
        "  #        mode='CONSTANT')\n",
        "  #sliced_foreground = tf.slice(padded_foreground,\n",
        "  #                                 time_shift_offset_placeholder_,\n",
        "  #                                 [desired_samples, -1])\n",
        "\n",
        "#get label for wave\n",
        "def get_label(file_path):\n",
        "   parts = tf.strings.split(file_path,os.path.sep)\n",
        "\n",
        "#you will use indexing here instead of tuple unpacking to enable this to in\n",
        "#work in a tensorflow graph\n",
        "   return parts[-2]\n",
        "\n",
        "def get_waveform_and_label(file_path):\n",
        "  label = get_label(file_path)\n",
        "  audio_bin = tf.io.read_file(file_path)\n",
        "  waveform= decode_audio(audio_bin)\n",
        "  return waveform,label"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDmsiaS2UoBB"
      },
      "source": [
        "#normailize inputs\n",
        "def normalize_waveforms(x):\n",
        "    \"\"\" notmalize each waveform of a set\n",
        "\n",
        "    parameters:\n",
        "    x: the dataset to normalize\n",
        "\n",
        "    returns:\n",
        "\n",
        "    the same set with each waveform normalized\n",
        "    \"\"\"\n",
        "\n",
        "    max_nums = np.max(np.absolute(x),axis=1)\n",
        "    zeros = np.where(max_nums==0)\n",
        "    max_nums[zeors] = 1\n",
        "    return x/max_nums[:,None]\n",
        "\n",
        "def normalize_spectrograms(x):\n",
        "    \"\"\"Normalize each spectrogram of a set\n",
        "    Parameters:\n",
        "    x: the dataset to normalize\n",
        "    Returns:\n",
        "    The same set with each spectrogram normalized.\n",
        "    \"\"\"\n",
        "    x_2 = np.zeros_like(x)\n",
        "    for i, example in enumerate(x):\n",
        "        x_2[i] = example/np.max(np.abs(example))\n",
        "\n",
        "    return x_2\n",
        "\n",
        "\n",
        "def normalize_2D(x):\n",
        "    \"\"\"Normalize a 2D image\n",
        "    \"\"\"\n",
        "\n",
        "    x_2 = deepcopy(x)\n",
        "    eps = 1e-10\n",
        "\n",
        "    means = np.mean(x_2, axis = (1,2))\n",
        "    std = np.std(x_2,axis = (1,2))\n",
        "\n",
        "    return (x_2-means[:,None,None])/(std[:,None,None]+eps)\n",
        "\n",
        "def make_oh(y):\n",
        "    N = len(y)\n",
        "    n_classes = len(np.unique(y))\n",
        "\n",
        "    y_oh = np.zeros((N,n_classes))\n",
        "\n",
        "    for i in range(N):\n",
        "        col = int(y[i])\n",
        "        y_oh[i,col] = 1\n",
        "\n",
        "    return y_oh"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1lPEEPA3Tru"
      },
      "source": [
        "#spectrgram conversio\n",
        "def get_spectrogram(waveform):\n",
        "  # Padding for files with less than 16000 samples\n",
        "  zero_padding = tf.zeros([_params.sample_rate] - tf.shape(waveform), dtype=tf.float32)\n",
        "\n",
        "  # Concatenate audio with padding so that all audio clips will be of the\n",
        "  # same length\n",
        "  waveform = tf.cast(waveform, tf.float32)\n",
        "  equal_length = tf.concat([waveform, zero_padding], 0)\n",
        "  window_size_samples = int(16000*_params.stft_window_useconds/1000)\n",
        "  window_size_stride =  int(16000*_params.stft_hop_useconds/1000)\n",
        "  fft_length = 2 ** int(np.ceil(np.log(window_size_samples)/ np.log(2.0)))\n",
        "  spectrogram = tf.signal.stft(\n",
        "     equal_length, frame_length=window_size_samples, frame_step=window_size_stride,fft_length=fft_length)\n",
        "  print('Spectrogram shape:', spectrogram.shape)\n",
        "  #spectrogram = audio_ops.audio_spectrogram(equal_length,window_size_samples,window_size_stride,magnitude_squared=True)\n",
        "  spectrogram = tf.abs(spectrogram)\n",
        "  # Warp the linear scale spectrograms into the mel-scale.\n",
        "  num_spectrogram_bins = fft_length // 2 + 1\n",
        "  print(\"number of mel_bands\", num_spectrogram_bins)\n",
        "  lower_edge_hertz, upper_edge_hertz, num_mel_bins = 80.0, 7600.0, 40\n",
        "  linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\n",
        "      _params.mel_bands, num_spectrogram_bins, _params.sample_rate, _params.mel_min_hz,_params.mel_max_hz)\n",
        "\n",
        "  #mel_spectrograms = tf.tensordot(\n",
        "  #          spectrogram, linear_to_mel_weight_matrix, 1)\n",
        "\n",
        "  mel_spectrograms = tf.matmul(spectrogram, linear_to_mel_weight_matrix)\n",
        "  mel_spectrograms.set_shape(spectrogram.shape[:-1].concatenate(\n",
        "                linear_to_mel_weight_matrix.shape[-1:]))\n",
        "\n",
        "\n",
        "  # Compute a stabilized log to get log-magnitude mel-scale spectrograms.\n",
        "  log_mel_spectrograms = tf.math.log(mel_spectrograms + 1e-6)\n",
        "\n",
        "  print(\"mel_spectrogram_shape\", log_mel_spectrograms.shape)\n",
        "\n",
        "  # Compute MFCCs from log_mel_spectrograms and take the first 40.\n",
        "  mfccs = tf.signal.mfccs_from_log_mel_spectrograms(\n",
        "        log_mel_spectrograms)[..., :64]\n",
        "\n",
        "  spectrogram = tf.abs(spectrogram)\n",
        "  print('mfcc shape:', mfccs.shape)\n",
        "  return spectrogram,mfccs\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kb-6kW3SgRmF"
      },
      "source": [
        "#mel spectrgram conversion\n",
        "def get_melspectrogram(waveform):\n",
        "  # Padding for files with less than 16000 samples\n",
        "  zero_padding = tf.zeros([_params.sample_rate] - tf.shape(waveform), dtype=tf.float32)\n",
        "\n",
        "  # Concatenate audio with padding so that all audio clips will be of the\n",
        "  # same length\n",
        "  waveform = tf.cast(waveform, tf.float32)\n",
        "  equal_length = tf.concat([waveform, zero_padding], 0)\n",
        "  window_size_samples = int(16000*_params.stft_window_useconds/1000)\n",
        "  window_size_stride =  int(16000*_params.stft_hop_useconds/1000)\n",
        "  fft_length = 2 ** int(np.ceil(np.log(window_size_samples)/ np.log(2.0)))\n",
        "  spectrogram = tf.signal.stft(\n",
        "     equal_length, frame_length=window_size_samples, frame_step=window_size_stride,fft_length=fft_length)\n",
        "  print('Spectrogram shape:', spectrogram.shape)\n",
        "  #spectrogram = audio_ops.audio_spectrogram(equal_length,window_size_samples,window_size_stride,magnitude_squared=True)\n",
        "  spectrogram = tf.abs(spectrogram)\n",
        "  # Warp the linear scale spectrograms into the mel-scale.\n",
        "  num_spectrogram_bins = fft_length // 2 + 1\n",
        "  print(\"number of mel_bands\", num_spectrogram_bins)\n",
        "  lower_edge_hertz, upper_edge_hertz, num_mel_bins = 80.0, 7600.0, 40\n",
        "  linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\n",
        "      _params.mel_bands, num_spectrogram_bins, _params.sample_rate, _params.mel_min_hz,_params.mel_max_hz)\n",
        "\n",
        "  #mel_spectrograms = tf.tensordot(\n",
        "  #          spectrogram, linear_to_mel_weight_matrix, 1)\n",
        "\n",
        "  mel_spectrograms = tf.matmul(spectrogram, linear_to_mel_weight_matrix)\n",
        "  mel_spectrograms.set_shape(spectrogram.shape[:-1].concatenate(\n",
        "                linear_to_mel_weight_matrix.shape[-1:]))\n",
        "\n",
        "\n",
        "  # Compute a stabilized log to get log-magnitude mel-scale spectrograms.\n",
        "  log_mel_spectrograms = tf.math.log(mel_spectrograms + 1e-6)\n",
        "\n",
        "  print(\"mel_spectrogram_shape\", log_mel_spectrograms.shape)\n",
        "\n",
        "  spectrogram = tf.abs(spectrogram)\n",
        "  return spectrogram,log_mel_spectrograms"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCWlOvh94Kh5"
      },
      "source": [
        "def get_spectrogram_and_label_id(audio, label):\n",
        "  spectrogram,mfccs= get_spectrogram(audio)\n",
        "  spectrogram = tf.expand_dims(spectrogram, -1)\n",
        "  #mfccs = tf.expand_dims(mfccs,1)\n",
        "  label_id = tf.argmax(label == kws_config.commands)\n",
        "  return spectrogram,label_id\n",
        "\n",
        "def get_melspectrogram_and_label_id(audio, label):\n",
        "  _,mel_spectrogram= get_melspectrogram(audio)\n",
        "  mel_spectrogram = tf.expand_dims(mel_spectrogram, -1)\n",
        "  label_id = tf.argmax(label == kws_config.commands)\n",
        "  return mel_spectrogram,label_id\n",
        "\n",
        "def preprocess_dataset(files):\n",
        "  files_ds = tf.data.Dataset.from_tensor_slices(files)\n",
        "  output_ds = files_ds.map(get_waveform_and_label, num_parallel_calls=kws_config.AUTOTUNE)\n",
        "  output_ds = output_ds.map(\n",
        "      get_spectrogram_and_label_id,  num_parallel_calls=kws_config.AUTOTUNE)\n",
        "  return output_ds\n",
        "\n",
        "def get_mfcc_and_label_id(audio, label):\n",
        "  spectrogram,mfccs = get_spectrogram(audio)\n",
        "  #spectrogram = tf.expand_dims(spectrogram, -1)\n",
        "  mfccs = tf.expand_dims(mfccs,-1)\n",
        "  label_id = tf.argmax(label == kws_config.commands)\n",
        "  return  mfccs, label_id\n",
        "\n",
        "def preprocess_mfccdataset(files):\n",
        "  files_ds = tf.data.Dataset.from_tensor_slices(files)\n",
        "  output_ds = files_ds.map(get_waveform_and_label, num_parallel_calls=kws_config.AUTOTUNE)\n",
        "  output_ds = output_ds.map(\n",
        "      get_mfcc_and_label_id,  num_parallel_calls=kws_config.AUTOTUNE)\n",
        "  return output_ds\n",
        "\n",
        "def preprocess_meldataset(files):\n",
        "  files_ds = tf.data.Dataset.from_tensor_slices(files)\n",
        "  output_ds = files_ds.map(get_waveform_and_label, num_parallel_calls=kws_config.AUTOTUNE)\n",
        "  output_ds = output_ds.map(\n",
        "      get_melspectrogram_and_label_id,  num_parallel_calls=kws_config.AUTOTUNE)\n",
        "  return output_ds"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTvBIWJkBoRE"
      },
      "source": [
        "#plotting utilities\n",
        "\n",
        "def plot_waveform(audio,label,ax):\n",
        "  ax.plot(audio.numpy())\n",
        "  ax.set_yticks(np.arange(-2.2, 2.2, 0.4))\n",
        "  label = label.numpy().decode('utf-8')\n",
        "  ax.set_title(label)\n",
        "\n",
        "def plot_spectrogram(spectrogram, ax):\n",
        "  # Convert to frequencies to log scale and transpose so that the time is\n",
        "  # represented in the x-axis (columns).\n",
        "  log_spec = np.log(spectrogram.T)\n",
        "  height = log_spec.shape[0]\n",
        "  width = log_spec.shape[1]\n",
        "  X = np.linspace(0, np.size(spectrogram), num=width, dtype=int)\n",
        "  Y = range(height)\n",
        "  ax.pcolormesh(X, Y, log_spec)\n",
        "\n",
        "def plot_audio(wave_ds):\n",
        "  \"\"\" function to plot audio wave (input)  \"\"\"\n",
        "  rows = 5\n",
        "  cols = 3\n",
        "  n = rows\n",
        "  for i, (audio, label) in enumerate(wave_ds.take(n)):\n",
        "    fig, axes = plt.subplots(3, figsize=(12, 10))\n",
        "    spectrogram,mfccs = get_spectrogram(audio)\n",
        "    timescale = np.arange(audio.shape[0])\n",
        "    axes[0].plot(timescale,audio.numpy())\n",
        "    label = label.numpy().decode('utf-8')\n",
        "    axes[0].set_title(label)\n",
        "    axes[0].set_xlim([0, 16000])\n",
        "    plot_spectrogram(spectrogram.numpy(),axes[1])\n",
        "    axes[1].set_title(\"spectrogram\")\n",
        "    plot_spectrogram(mfccs.numpy(),axes[2])\n",
        "    axes[2].set_title(\"mfcc\")\n",
        "  plt.show()\n",
        "\n",
        "def plot_spectrogram(spectrogram_ds):\n",
        "  \"\"\" function to plot spectrogram (input)  \"\"\"\n",
        "  rows = 5\n",
        "  cols = 5\n",
        "  n = rows*cols\n",
        "  fig, axes = plt.subplots(rows, cols, figsize=(20, 20))\n",
        "  for i, (spectrogram, label_id) in enumerate(spectrogram_ds.take(n)):\n",
        "    r = i // cols\n",
        "    c = i % cols\n",
        "    ax = axes[r][c]\n",
        "    print(\"spectrogram_shape\",spectrogram.shape)\n",
        "    plot_spectrogram(np.squeeze(spectrogram.numpy()), ax)\n",
        "    ax.set_title(kws_config.commands[label_id.numpy()])\n",
        "    ax.axis('off')\n",
        "  plt.show()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkHb7_-j4SaN"
      },
      "source": [
        "#data utilities\n",
        "def get_spectrogram_data(train_files,val_files,test_files):\n",
        "  AUTOTUNE = tf.data.AUTOTUNE\n",
        "  train_ds = preprocess_dataset(train_files)\n",
        "  val_ds = preprocess_dataset(val_files)\n",
        "  test_ds = preprocess_dataset(test_files)\n",
        "  return train_ds,val_ds,test_ds\n",
        "\n",
        "def get_mfcc_data(train_files,val_files,test_files):\n",
        "  AUTOTUNE = tf.data.AUTOTUNE\n",
        "  train_ds = preprocess_mfccdataset(train_files)\n",
        "  val_ds = preprocess_mfccdataset(val_files)\n",
        "  test_ds = preprocess_mfccdataset(test_files)\n",
        "  return train_ds,val_ds,test_ds\n",
        "\n",
        "def get_mel_data(train_files,val_files,test_files):\n",
        "  AUTOTUNE = tf.data.AUTOTUNE\n",
        "  train_ds = preprocess_meldataset(train_files)\n",
        "  val_ds = preprocess_meldataset(val_files)\n",
        "  test_ds = preprocess_meldataset(test_files)\n",
        "  return train_ds,val_ds,test_ds"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1umqhMY4f8G"
      },
      "source": [
        "def build_mfccdata():\n",
        "  train_files,val_files,test_files = get_data_split(kws_config.DATADIR_PATH)\n",
        "  train_ds,val_ds,test_ds = get_mfcc_data(train_files,val_files,test_files)\n",
        "  kws_config.commands = get_commands(kws_config.DATADIR_PATH+'/mini_speech_commands')\n",
        "  return train_ds,val_ds,test_ds\n",
        "\n",
        "def build_meldata():\n",
        "  train_files,val_files,test_files = get_data_split(kws_config.DATADIR_PATH)\n",
        "  train_ds,val_ds,test_ds = get_mel_data(train_files,val_files,test_files)\n",
        "  kws_config.commands = get_commands(kws_config.DATADIR_PATH+'/mini_speech_commands')\n",
        "  return train_ds,val_ds,test_ds"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = kws_config.DATADIR_PATH + '/mini_speech_commands'\n",
        "go_filenames = tf.io.gfile.glob(str(data_dir) + '/go/*')\n",
        "no_filenames = tf.io.gfile.glob(str(data_dir) + '/no/*')\n",
        "gofiles_ds = tf.data.Dataset.from_tensor_slices(go_filenames)\n",
        "nofiles_ds = tf.data.Dataset.from_tensor_slices(no_filenames)\n",
        "gowaveform_ds = gofiles_ds.map(get_waveform_and_label, num_parallel_calls=AUTOTUNE)\n",
        "nowaveform_ds = nofiles_ds.map(get_waveform_and_label, num_parallel_calls=AUTOTUNE)"
      ],
      "metadata": {
        "id": "Xpq0SRzOEM4-"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfXkCWbtlHRr"
      },
      "source": [
        "# Final Architecture with Data Augmentations\n",
        "def setup_tinymodel(input_shape,num_labels,norm_layer):\n",
        "  tiny_model = models.Sequential([\n",
        "    layers.Input(shape=input_shape),\n",
        "    norm_layer,\n",
        "    #layers.RandomRotation(factor = 0.5),\n",
        "    #layers.RandomFlip(),\n",
        "    #layers.RandomContrast(factor = 0.5),\n",
        "    layers.Conv2D(64, kernel_size=(8,8), padding='valid', strides=(1,1), activation='relu'),\n",
        "    layers.MaxPooling2D(pool_size=(1,1)),\n",
        "    layers.LayerNormalization(),\n",
        "    layers.Conv2D(48, kernel_size=(4,4), padding='valid', strides=(1,1), activation='relu'),\n",
        "    layers.MaxPooling2D(pool_size=(1,1)),\n",
        "    layers.LayerNormalization(),\n",
        "    layers.GlobalMaxPooling2D(),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(num_labels),])\n",
        "  tiny_model.summary()\n",
        "  return tiny_model\n",
        "\n",
        "def lr_scheduler(epoch, lr):\n",
        "    if epoch > 4:\n",
        "        lr = 0.0001 *  tf.math.exp(0.1 * (7 - epoch))\n",
        "        return lr\n",
        "    return lr\n",
        "\n",
        "def make_tinymodel(input_shape,num_labels,norm_layer):\n",
        "  model = setup_tinymodel(input_shape,num_labels,norm_layer)\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=kws_config.LEARNING_RATE)\n",
        "  model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy'],\n",
        "  )\n",
        "  return model\n",
        "\n",
        "def get_callbacks(checkpoint_path, callbacks = tf.keras.callbacks):\n",
        "  \"\"\"\n",
        "  Function to declare the callbacks\n",
        "  \"\"\"\n",
        "  early_stopping = callbacks.EarlyStopping(\n",
        "      min_delta=0.01, # minimium amount of change to count as an improvement\n",
        "      patience=20, # how many epochs to wait before stopping\n",
        "      restore_best_weights=True,\n",
        "  )\n",
        "  # Create a callback that saves the model's weights\n",
        "  checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "      filepath=checkpoint_path,\n",
        "      save_weights_only=True,\n",
        "      )\n",
        "  # Define the callbacks\n",
        "  kws_config.log_dir = kws_config.DIRECTORY_PATH+\"/logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "  callbacks = [\n",
        "      tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1),\n",
        "      early_stopping,\n",
        "      tf.keras.callbacks.LearningRateScheduler(lr_scheduler, verbose=1),\n",
        "      checkpoint_callback,\n",
        "  ]\n",
        "  return callbacks\n",
        "\n",
        "def run_model(checkpoint_path):\n",
        "  \"\"\"\n",
        "  Function to fit the model on the dataset and report the training time\n",
        "  \"\"\"\n",
        "  train_ds,val_ds,test_ds = build_mfccdata()\n",
        "  for mfcc,_ in train_ds.take(1):\n",
        "    input_shape = mfcc.shape\n",
        "  num_labels = len(kws_config.commands)\n",
        "  print(num_labels)\n",
        "  norm_layer = preprocessing.Normalization()\n",
        "  norm_layer.adapt(train_ds.map(lambda x, _: x))\n",
        "  model = make_tinymodel(input_shape,num_labels,norm_layer)\n",
        "  callbacks = get_callbacks(checkpoint_path = checkpoint_path)\n",
        "\n",
        "  train_ds = train_ds.batch(kws_config.BATCH_SIZE)\n",
        "  val_ds = val_ds.batch(kws_config.BATCH_SIZE)\n",
        "\n",
        "  train_ds = train_ds.cache().prefetch(kws_config.AUTOTUNE)\n",
        "  val_ds = val_ds.cache().prefetch(kws_config.AUTOTUNE)\n",
        "\n",
        "  # Train model and save history\n",
        "  start = time.time()\n",
        "  history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=kws_config.NUM_EPOCHS,\n",
        "    callbacks=callbacks,\n",
        "  )\n",
        "  end = time.time()\n",
        "  print(f\"Total Time taken for Model Training: {end - start} seconds.\")\n",
        "  plot_accuracy(history)\n",
        "  test_model(model,test_ds)\n",
        "  return history,model\n",
        "\n",
        "def test_model(model,test_ds):\n",
        "  test_audio = []\n",
        "  test_labels = []\n",
        "\n",
        "  for audio, label in test_ds:\n",
        "    test_audio.append(audio.numpy())\n",
        "    test_labels.append(label.numpy())\n",
        "\n",
        "  test_audio = np.array(test_audio)\n",
        "  test_labels = np.array(test_labels)\n",
        "\n",
        "  y_pred = np.argmax(model.predict(test_audio), axis=1)\n",
        "  y_true = test_labels\n",
        "\n",
        "  test_acc = sum(y_pred == y_true) / len(y_true)\n",
        "  print(f'Test set accuracy: {test_acc:.0%}')\n",
        "\n",
        "  confusion_mtx = tf.math.confusion_matrix(y_true, y_pred)\n",
        "  plt.figure(figsize=(10, 8))\n",
        "  sns.heatmap(confusion_mtx, xticklabels=commands, yticklabels=commands,\n",
        "            annot=True, fmt='g')\n",
        "  plt.xlabel('Prediction')\n",
        "  plt.ylabel('Label')\n",
        "  plt.show()\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#norm_layer = preprocessing.Normalization()\n",
        "  #norm_layer.adapt(train_ds.map(lambda x, _: x))\n",
        "tiny_his,model = run_model(kws_config.BASELINE_CHECKPOINT_PATH)\n"
      ],
      "metadata": {
        "id": "j4te6ZmrVyre",
        "outputId": "50d4e4af-115a-4ba7-b33d-c67de091577a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of total examples: 8000\n",
            "Commands: ['yes' 'up' 'right' 'stop' 'down' 'go' 'left' 'no']\n",
            "Number of examples per label: 1000\n",
            "Training set size 6400\n",
            "Validation set size 1600\n",
            "Test set size 1600\n",
            "Spectrogram shape: (98, 257)\n",
            "number of mel_bands 257\n",
            "mel_spectrogram_shape (98, 40)\n",
            "mfcc shape: (98, 40)\n",
            "Spectrogram shape: (98, 257)\n",
            "number of mel_bands 257\n",
            "mel_spectrogram_shape (98, 40)\n",
            "mfcc shape: (98, 40)\n",
            "Spectrogram shape: (98, 257)\n",
            "number of mel_bands 257\n",
            "mel_spectrogram_shape (98, 40)\n",
            "mfcc shape: (98, 40)\n",
            "Commands: ['yes' 'up' 'right' 'stop' 'down' 'go' 'left' 'no']\n",
            "8\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " normalization_5 (Normaliza  (None, 98, 40, 1)         3         \n",
            " tion)                                                           \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 91, 33, 64)        4160      \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPooli  (None, 91, 33, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " layer_normalization_10 (La  (None, 91, 33, 64)        128       \n",
            " yerNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 88, 30, 48)        49200     \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPooli  (None, 88, 30, 48)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " layer_normalization_11 (La  (None, 88, 30, 48)        96        \n",
            " yerNormalization)                                               \n",
            "                                                                 \n",
            " global_max_pooling2d_5 (Gl  (None, 48)                0         \n",
            " obalMaxPooling2D)                                               \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 48)                0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 32)                1568      \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 128)               4224      \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 8)                 1032      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 60411 (235.98 KB)\n",
            "Trainable params: 60408 (235.97 KB)\n",
            "Non-trainable params: 3 (16.00 Byte)\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 1/150\n",
            "100/100 [==============================] - 33s 291ms/step - loss: 1.5219 - accuracy: 0.4611 - val_loss: 0.7864 - val_accuracy: 0.7219 - lr: 0.0010\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 2/150\n",
            "100/100 [==============================] - 7s 70ms/step - loss: 0.4583 - accuracy: 0.8534 - val_loss: 0.3674 - val_accuracy: 0.8781 - lr: 0.0010\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 3/150\n",
            "100/100 [==============================] - 7s 71ms/step - loss: 0.2554 - accuracy: 0.9144 - val_loss: 0.2881 - val_accuracy: 0.9069 - lr: 0.0010\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 4/150\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.1873 - accuracy: 0.9392 - val_loss: 0.3420 - val_accuracy: 0.8888 - lr: 0.0010\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 5/150\n",
            "100/100 [==============================] - 7s 69ms/step - loss: 0.1675 - accuracy: 0.9444 - val_loss: 0.2695 - val_accuracy: 0.9150 - lr: 0.0010\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.000122140278108418.\n",
            "Epoch 6/150\n",
            "100/100 [==============================] - 7s 68ms/step - loss: 0.0932 - accuracy: 0.9719 - val_loss: 0.2116 - val_accuracy: 0.9281 - lr: 1.2214e-04\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.00011051709589082748.\n",
            "Epoch 7/150\n",
            "100/100 [==============================] - 7s 69ms/step - loss: 0.0693 - accuracy: 0.9817 - val_loss: 0.2121 - val_accuracy: 0.9294 - lr: 1.1052e-04\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 9.999999747378752e-05.\n",
            "Epoch 8/150\n",
            "100/100 [==============================] - 7s 68ms/step - loss: 0.0603 - accuracy: 0.9839 - val_loss: 0.2142 - val_accuracy: 0.9287 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 9.048373613040894e-05.\n",
            "Epoch 9/150\n",
            "100/100 [==============================] - 7s 68ms/step - loss: 0.0542 - accuracy: 0.9866 - val_loss: 0.2159 - val_accuracy: 0.9312 - lr: 9.0484e-05\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 8.187307685147971e-05.\n",
            "Epoch 10/150\n",
            "100/100 [==============================] - 7s 68ms/step - loss: 0.0496 - accuracy: 0.9881 - val_loss: 0.2182 - val_accuracy: 0.9306 - lr: 8.1873e-05\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 7.408182136714458e-05.\n",
            "Epoch 11/150\n",
            "100/100 [==============================] - 7s 70ms/step - loss: 0.0457 - accuracy: 0.9894 - val_loss: 0.2198 - val_accuracy: 0.9312 - lr: 7.4082e-05\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 6.703200051560998e-05.\n",
            "Epoch 12/150\n",
            "100/100 [==============================] - 7s 70ms/step - loss: 0.0426 - accuracy: 0.9906 - val_loss: 0.2219 - val_accuracy: 0.9319 - lr: 6.7032e-05\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 6.065306661184877e-05.\n",
            "Epoch 13/150\n",
            "100/100 [==============================] - 7s 68ms/step - loss: 0.0399 - accuracy: 0.9914 - val_loss: 0.2241 - val_accuracy: 0.9306 - lr: 6.0653e-05\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 5.488115857588127e-05.\n",
            "Epoch 14/150\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.0376 - accuracy: 0.9919 - val_loss: 0.2255 - val_accuracy: 0.9294 - lr: 5.4881e-05\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 4.9658530770102516e-05.\n",
            "Epoch 15/150\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0355 - accuracy: 0.9925 - val_loss: 0.2277 - val_accuracy: 0.9306 - lr: 4.9659e-05\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 4.493289452511817e-05.\n",
            "Epoch 16/150\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.0338 - accuracy: 0.9934 - val_loss: 0.2288 - val_accuracy: 0.9287 - lr: 4.4933e-05\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 4.065696703037247e-05.\n",
            "Epoch 17/150\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.0321 - accuracy: 0.9937 - val_loss: 0.2307 - val_accuracy: 0.9281 - lr: 4.0657e-05\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 3.678794746519998e-05.\n",
            "Epoch 18/150\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.0308 - accuracy: 0.9941 - val_loss: 0.2321 - val_accuracy: 0.9281 - lr: 3.6788e-05\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 3.3287105907220393e-05.\n",
            "Epoch 19/150\n",
            "100/100 [==============================] - 7s 69ms/step - loss: 0.0295 - accuracy: 0.9945 - val_loss: 0.2335 - val_accuracy: 0.9294 - lr: 3.3287e-05\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 3.0119417715468444e-05.\n",
            "Epoch 20/150\n",
            "100/100 [==============================] - 7s 68ms/step - loss: 0.0284 - accuracy: 0.9950 - val_loss: 0.2348 - val_accuracy: 0.9294 - lr: 3.0119e-05\n",
            "\n",
            "Epoch 21: LearningRateScheduler setting learning rate to 2.7253179723629728e-05.\n",
            "Epoch 21/150\n",
            "100/100 [==============================] - 7s 68ms/step - loss: 0.0274 - accuracy: 0.9952 - val_loss: 0.2361 - val_accuracy: 0.9300 - lr: 2.7253e-05\n",
            "\n",
            "Epoch 22: LearningRateScheduler setting learning rate to 2.465969737386331e-05.\n",
            "Epoch 22/150\n",
            "100/100 [==============================] - 7s 70ms/step - loss: 0.0265 - accuracy: 0.9953 - val_loss: 0.2370 - val_accuracy: 0.9312 - lr: 2.4660e-05\n",
            "\n",
            "Epoch 23: LearningRateScheduler setting learning rate to 2.2313015506369993e-05.\n",
            "Epoch 23/150\n",
            "100/100 [==============================] - 7s 70ms/step - loss: 0.0257 - accuracy: 0.9953 - val_loss: 0.2380 - val_accuracy: 0.9319 - lr: 2.2313e-05\n",
            "\n",
            "Epoch 24: LearningRateScheduler setting learning rate to 2.0189649148960598e-05.\n",
            "Epoch 24/150\n",
            "100/100 [==============================] - 7s 69ms/step - loss: 0.0250 - accuracy: 0.9955 - val_loss: 0.2388 - val_accuracy: 0.9319 - lr: 2.0190e-05\n",
            "\n",
            "Epoch 25: LearningRateScheduler setting learning rate to 1.8268350686412305e-05.\n",
            "Epoch 25/150\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.0244 - accuracy: 0.9956 - val_loss: 0.2397 - val_accuracy: 0.9312 - lr: 1.8268e-05\n",
            "\n",
            "Epoch 26: LearningRateScheduler setting learning rate to 1.6529889762750827e-05.\n",
            "Epoch 26/150\n",
            "100/100 [==============================] - 7s 70ms/step - loss: 0.0238 - accuracy: 0.9958 - val_loss: 0.2406 - val_accuracy: 0.9306 - lr: 1.6530e-05\n",
            "Total Time taken for Model Training: 241.6335368156433 seconds.\n",
            "50/50 [==============================] - 1s 15ms/step\n",
            "Test set accuracy: 93%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4B3FaDoFg-u"
      },
      "source": [
        "def setup_cnnmodel(input_shape,num_labels,norm_layer,padding='valid',pool1=(2,2), pool2=(2,2),dropout_rate1=0.5, dropout_rate2=0.5,\n",
        "                    strides1=(20,8),strides2=(10,4),cnn1_features=64,cnn2_features=64,dnn_features1=128, dnn_features2=128,\n",
        "                    kernel1_size=(3,3),kernel2_size=(3,3)):\n",
        "   model = models.Sequential([\n",
        "        layers.Input(shape=input_shape),\n",
        "        norm_layer,\n",
        "        layers.Conv2D(cnn1_features,padding=padding, kernel_size=kernel1_size, strides=strides1,activation='gelu',use_bias=True,bias_initializer='zeros'),\n",
        "        layers.MaxPool2D(pool_size=pool1),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(cnn2_features, padding=padding,kernel_size=kernel2_size, strides=strides2,activation='gelu',use_bias=True,bias_initializer='zeros'),\n",
        "        layers.MaxPool2D(pool_size=pool2),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.GlobalMaxPooling2D(),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(dnn_features2, activation='relu',use_bias=True,bias_initializer='zeros'),\n",
        "        layers.Dense(dnn_features1, activation='relu',use_bias=True,bias_initializer='zeros'),\n",
        "        layers.Dense(num_labels),])\n",
        "   model.summary()\n",
        "   return model\n",
        "\n",
        "def getFeatureMap():\n",
        "    earlyPredictor = tf.keras.Model(test_model.inputs,test_model.get_layer(index=2).output)\n",
        "    feature_maps = earlyPredictor.predict(test_img)[0]\n",
        "    ix = 1\n",
        "    figure,axes = plt.subplots(8,8,figsize=(12,12))\n",
        "    for i  in range(64):\n",
        "       r = i // 8\n",
        "       c = i % 8\n",
        "       spectrogram = feature_maps[:,:,ix-1]\n",
        "       ax = axes[r][c]\n",
        "       ax.pcolormesh(40, 4, spectrogram)\n",
        "       ix += 1\n",
        "    return figure\n",
        "\n",
        "\n",
        "def plot_to_image(figure): #Convert the image into the tensor format\n",
        "  \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
        "  returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
        "  # Save the plot to a PNG in memory.\n",
        "  buf = io.BytesIO()\n",
        "  plt.savefig(buf, format='png')\n",
        "  # Closing the figure prevents it from being displayed directly inside\n",
        "  # the notebook.\n",
        "  plt.close(figure)\n",
        "  buf.seek(0)\n",
        "  # Convert PNG buffer to TF image\n",
        "  image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
        "  # Add the batch dimension\n",
        "  image = tf.expand_dims(image, 0)\n",
        "  return image\n",
        "\n",
        "\n",
        "def learningrate_scheduler_image(epoch,lr):\n",
        "  if epoch > 5:\n",
        "     lr = 0.0001\n",
        "  tf.summary.scalar('learning rate', data=lr, step=epoch)\n",
        "  figure = getFeatureMap()\n",
        "  with kws_config.file_writer_image.as_default():\n",
        "    tf.summary.image(\"Feature Map\", plot_to_image(figure), step=epoch)\n",
        "  return lr\n",
        "\n",
        "\n",
        "def plot_accuracy(history):\n",
        "  print(\"\\n\")\n",
        "  print(\"\\n\")\n",
        "  print(\"Plotting accuracy metric\")\n",
        "  print(\"\\n\")\n",
        "  print(\"\\n\")\n",
        "  metrics = history.history\n",
        "  plt.plot(history.epoch, metrics['loss'], metrics['val_loss'])\n",
        "  plt.legend(['loss', 'val_loss'])\n",
        "  plt.show()\n",
        "\n",
        "def inference(model, sample_file):\n",
        "   #sample_file = data_dir/'no/01bb6a2a_nohash_0.wav'\n",
        "   sample_ds = preprocess_mfccdataset([str(sample_file)])\n",
        "   for spectrogram, label in sample_ds.batch(1):\n",
        "      prediction = model(spectrogram)\n",
        "      plt.bar(kws_config.commands, tf.nn.softmax(prediction[0]))\n",
        "      plt.title(f'Predictions for \"{kws_config.commands[label[0]]}\"')\n",
        "      plt.show()\n",
        "\n",
        "def make_cnnmodel(input_shape,num_labels,norm_layer):\n",
        "  model = setup_cnnmodel(input_shape,num_labels,norm_layer,padding='same',pool1=(1,3), pool2=(1,1),dropout_rate1=0.25, dropout_rate2=0.5,\n",
        "                    strides1=(1,1),strides2=(1,1),cnn1_features=64,cnn2_features=64,dnn_features1=128, dnn_features2=32,\n",
        "                    kernel1_size=(20,8),kernel2_size=(10,4))\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=kws_config.LEARNING_RATE)\n",
        "  model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy'],\n",
        "  )\n",
        "  return model\n",
        "\n",
        "def run_cnnmodel(checkpoint_path):\n",
        "  \"\"\"\n",
        "  Function to fit the model on the dataset and report the training time\n",
        "  \"\"\"\n",
        "  train_ds,val_ds,test_ds = build_mfccdata()\n",
        "  for mfcc,_ in train_ds.take(1):\n",
        "    input_shape = mfcc.shape\n",
        "  num_labels = len(kws_config.commands)\n",
        "  norm_layer = preprocessing.Normalization()\n",
        "  norm_layer.adapt(train_ds.map(lambda x, _: x))\n",
        "  model = make_cnnmodel(input_shape,num_labels,norm_layer)\n",
        "  callbacks = get_callbacks(checkpoint_path = checkpoint_path)\n",
        "\n",
        "  train_ds = train_ds.batch(kws_config.BATCH_SIZE)\n",
        "  val_ds = val_ds.batch(kws_config.BATCH_SIZE)\n",
        "\n",
        "  train_ds = train_ds.cache().prefetch(kws_config.AUTOTUNE)\n",
        "  val_ds = val_ds.cache().prefetch(kws_config.AUTOTUNE)\n",
        "\n",
        "  # Train model and save history\n",
        "  start = time.time()\n",
        "  history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=kws_config.NUM_EPOCHS,\n",
        "    callbacks=callbacks,\n",
        "  )\n",
        "  end = time.time()\n",
        "  print(f\"Total Time taken for Model Training: {end - start} seconds.\")\n",
        "\n",
        "  plot_accuracy(history)\n",
        "\n",
        "  test_model(model,test_ds)\n",
        "  return history,model"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kws_config.model_name = \"cnn_tstride\"\n",
        "checkpoint_path = kws_config.BASELINE_CHECKPOINT_PATH\n",
        "cnn_his,model = run_cnnmodel(kws_config.BASELINE_CHECKPOINT_PATH)"
      ],
      "metadata": {
        "id": "cZLcht1ojJlO"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rc_PozqpLW4N"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rt0ewmRnJufG"
      },
      "source": [
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "ufGAvL_jdU59",
        "outputId": "eadca878-4d5b-4eb7-e1c9-fc8add02e341"
      },
      "source": [
        "sample_file = data_dir/'no/0132a06d_nohash_1.wav'\n",
        "#sample_file = data_dir/'go/004ae714_nohash_0.wav'\n",
        "#sample_file = data_dir/'left/00b01445_nohash_0.wav'\n",
        "sample_ds =  preprocess_mfccdataset([str(sample_file)])\n",
        "\n",
        "\n",
        "for spectrogram, label in sample_ds.batch(1):\n",
        "  prediction = model(spectrogram)\n",
        "  plt.bar(kws_config.commands, tf.nn.softmax(prediction[0]))\n",
        "  plt.title(f'Predictions for \"{kws_config.commands[label[0]]}\"')\n",
        "  plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spectrogram shape: (98, 257)\n",
            "number of mel_bands 257\n",
            "mel_spectrogram_shape (98, 40)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "4Ypr90g4BpGl",
        "outputId": "21c0bfb5-07d9-4f4a-90ae-c0031c55eab5"
      },
      "source": [
        "#run inference\n",
        "\n",
        "sample_file = data_dir/'no/0132a06d_nohash_1.wav'\n",
        "#sample_file = data_dir/'go/004ae714_nohash_0.wav'\n",
        "#sample_file = data_dir/'left/00b01445_nohash_0.wav'\n",
        "sample_ds =  preprocess_mfccdataset([str(sample_file)])\n",
        "\n",
        "\n",
        "for spectrogram, label in sample_ds.batch(1):\n",
        "  prediction = model(spectrogram)\n",
        "  plt.bar(kws_config.commands, tf.nn.softmax(prediction[0]))\n",
        "  plt.title(f'Predictions for \"{kws_config.commands[label[0]]}\"')\n",
        "  plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spectrogram shape: (98, 257)\n",
            "number of mel_bands 257\n",
            "mel_spectrogram_shape (98, 40)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPJGIR7MLaMp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "outputId": "1118c95a-52c9-4b25-d8b2-f3c2f3a3a38e"
      },
      "source": [
        "confusion_mtx = tf.math.confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(confusion_mtx, xticklabels=commands, yticklabels=commands,\n",
        "            annot=True, fmt='g')\n",
        "plt.xlabel('Prediction')\n",
        "plt.ylabel('Label')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}